{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified till 374"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automating driver for scraping and downloading recipes' images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  0\n",
      "Found  1\n",
      "Found  2\n",
      "Found  3\n",
      "Found  4\n",
      "Found  5\n",
      "Found  6\n",
      "Found  7\n",
      "not able to load img \n",
      "not able to load img \n",
      "not able to load img \n",
      "Found  8\n",
      "Found  9\n",
      "not able to load img \n",
      "Found  0\n",
      "not able to load img \n",
      "Found  1\n",
      "Found  2\n",
      "Found  3\n",
      "Found  4\n",
      "Found  5\n",
      "Found  6\n",
      "Found  7\n",
      "not able to load img \n",
      "not able to load img \n",
      "Found  8\n",
      "not able to load img \n",
      "not able to load img \n",
      "not able to load img \n",
      "not able to load img \n",
      "not able to load img \n",
      "Found  9\n",
      "Found  0\n",
      "Found  1\n",
      "Found  2\n",
      "Found  3\n",
      "Found  4\n",
      "Found  5\n",
      "Found  6\n",
      "Found  7\n",
      "Found  8\n",
      "Found  9\n",
      "Found  0\n",
      "Found  1\n",
      "Found  2\n",
      "Found  3\n",
      "Found  4\n",
      "not able to load img \n",
      "Found  5\n",
      "not able to load img \n",
      "Found  6\n",
      "Found  7\n",
      "Found  8\n",
      "Found  9\n",
      "Found  0\n",
      "not able to load img \n",
      "Found  1\n",
      "Found  2\n",
      "Found  3\n",
      "Found  4\n",
      "not able to load img \n",
      "Found  5\n",
      "Found  6\n",
      "Found  7\n",
      "Found  8\n",
      "Found  9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "import urllib3\n",
    "#335 to 668 incl\n",
    "\n",
    "#checking if the image can load with a good value of timeout\n",
    "def fetch_image_content_from_url(url,timeout):\n",
    "    try:\n",
    "        http = urllib3.PoolManager(timeout=urllib3.Timeout(connect=None, read=None, total=timeout))\n",
    "        response = http.request('GET', url)\n",
    "        return response.data\n",
    "    except Exception as e:\n",
    "        print(\"Exception occurred inside fetch_image_content_from_url\\n\",e)\n",
    "        \n",
    "\n",
    "#download particular image and saving as 'filename'   \n",
    "def download_image(download_path,url,filename):\n",
    "    try:\n",
    "        image_content = fetch_image_content_from_url(url,200)#fetching content of the image with a 200s timeout loading time\n",
    "        #requests.get(url,timeout=10)\n",
    "        image_bytes = io.BytesIO(image_content)#converting to bytes\n",
    "        file_path = os.path.join(download_path,filename)#creating filepath for image\n",
    "        image = Image.open(image_bytes)#opening the image\n",
    "        _image=image.convert(\"RGB\")#converting to RGB format since png format(which contains RGBA) gives error while downloading\n",
    "        with open(file_path,\"wb\") as f:\n",
    "            _image.save(f,\"JPEG\")\n",
    "    except Exception as e:\n",
    "        print(\"Exception is \", e)\n",
    "        \n",
    "        \n",
    "def download_images(download_folder_path,urls,recipe,recipe_index,train_imgs_count):\n",
    "    try:\n",
    "        recipe_folder_name = str(recipe_index) + \"_\" + recipe\n",
    "        train_folder_path = os.path.join(download_folder_path,\"train\",recipe_folder_name)\n",
    "        test_folder_path = os.path.join(download_folder_path,\"test\",recipe_folder_name)\n",
    "\n",
    "        if not os.path.exists(train_folder_path):\n",
    "            os.makedirs(train_folder_path)\n",
    "        if not os.path.exists(test_folder_path):\n",
    "            os.makedirs(test_folder_path)\n",
    "            \n",
    "        img_number = 1\n",
    "        for url in urls:\n",
    "            if img_number <= train_imgs_count:\n",
    "                download_image(train_folder_path,url,str(img_number)+\"_\"+recipe+\".jpg\")\n",
    "            else:\n",
    "                download_image(test_folder_path,url,str(img_number)+\"_\"+recipe+\".jpg\")\n",
    "            img_number+=1\n",
    "    except Exception as e:\n",
    "        print(\"Exception is \", e)\n",
    "        #log_urls(image_urls,recipe_index_csv,recipe,\"dwd_logs.txt\",no_of_img_to_train)\n",
    "        \n",
    "def log_urls(image_urls,recipe_index_csv,recipe,path_to_download_logs,train_imgs_count,ignore_msgs=False):\n",
    "    try:\n",
    "        with open(path_to_download_logs,\"a\") as f:\n",
    "            f.write(str(recipe_index_csv)+\"->\"+ recipe +\"\\n\")\n",
    "            f.write(\"$$$$\\n\") # mark the start delimiter\n",
    "            logged_urls = 0\n",
    "            for url in image_urls:\n",
    "                if logged_urls < train_imgs_count:\n",
    "                    f.write(\"train:>\"+url+\"\\n\")\n",
    "                else:\n",
    "                    f.write(\"test:>\" + url+\"\\n\")\n",
    "                logged_urls+=1\n",
    "            f.write(\"$$$$\\n\")\n",
    "            f.write(\"\\n\") # one empty line between end delimiter and new recipe\n",
    "            f.flush()\n",
    "        \n",
    "    except Exception as e:\n",
    "        if not ignore_msgs:\n",
    "            print(\"Exception occurred while logging urls\\n\",e)\n",
    "            \n",
    "driver=None   \n",
    "        \n",
    "def create_driver_and_load(cService,Options):\n",
    "    global driver\n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=cService,options=Options)\n",
    "        driver.maximize_window()\n",
    "        driver.get('https://images.google.com/')\n",
    "        time.sleep(7)\n",
    "    except Exception as e :\n",
    "        print(\"Exception occurred creating driver \\n\",e)         \n",
    "\n",
    "# change to joinpath\n",
    "PATH=\"C:\\\\Users\\\\Aarush Raj\\\\OneDrive\\\\Desktop\\\\img2rec\\\\venv\\\\chromedriver.exe\"\n",
    "chrome_service=webdriver.ChromeService(executable_path=PATH)\n",
    "chrome_options=Options()\n",
    "chrome_options.add_experimental_option(\"detach\",True)\n",
    "\n",
    "\n",
    "try:\n",
    "    # wait for search results to load\n",
    "    start = 364\n",
    "    row_count= 5\n",
    "    big_delay = 7\n",
    "    small_delay = 3\n",
    "    max_imgs = 10 \n",
    "    extra_imgs = 5\n",
    "    #batch_size = 2#change to 10 later\n",
    "    no_of_img_to_train=8\n",
    "    max_attempts_driver=0\n",
    "\n",
    "    create_driver_and_load(chrome_service,chrome_options)\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\Aarush Raj\\\\OneDrive\\\\Desktop\\\\img2rec\\\\DEEP-CHEF-PROJECT\\\\links_copy_main.csv\",skiprows= start,nrows=row_count,names=['name','link'])\n",
    "    d_log=open(\"dwd_logs.txt\",\"a\")\n",
    "    \n",
    "    # download images\n",
    "    for i in range(len(df['name'])):\n",
    "        recipe=df.loc[i,'name']\n",
    "        recipe_name=recipe\n",
    "        recipe=recipe_name + \" Recipe OR \" + recipe_name + \" Dish\"\n",
    "        recipe_index_csv=i+start\n",
    "        \n",
    "        #d_log.write(str(recipe_index_csv)+\"->\"+ recipe +\"\\n\")\n",
    "        d_log.flush()\n",
    "        \n",
    "        \"\"\"driver=webdriver.Chrome(service=chrome_service,options=chrome_options)\n",
    "        driver.maximize_window()\n",
    "        driver.get('https://images.google.com/')\n",
    "        time.sleep(7)\"\"\"\n",
    "        search_box = driver.find_element(By.NAME,\"q\")\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(recipe)\n",
    "        search_box.send_keys(Keys.ENTER)\n",
    "        time.sleep(10)\n",
    "    \n",
    "        image_urls=list()\n",
    "        # click on the first image\n",
    "        thumbnails = driver.find_elements(By.CLASS_NAME,\"mNsIhb\")\n",
    "        \"\"\"while len(thumbnails) < (max_imgs + extra_imgs): # checking condition before scrolling to minimize HTTP Requests\n",
    "            print(\"Less images obtained\")\n",
    "            time.sleep(small_delay)\n",
    "            driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "            time.sleep(small_delay)\n",
    "            thumbnails = driver.find_elements(By.CLASS_NAME,\"mNsIhb\") \n",
    "        \"\"\"  \n",
    "        \n",
    "        if(len(thumbnails)<(max_imgs + extra_imgs)):\n",
    "            print(\"quitting driver\")\n",
    "            driver.quit()\n",
    "            print(\"creating new driver\")\n",
    "            create_driver_and_load(chrome_service,chrome_options)\n",
    "            max_attempts_driver+=1\n",
    "            if(max_attempts_driver>=3):\n",
    "                raise\n",
    "            i-=1\n",
    "            \n",
    "        x=len(image_urls)\n",
    "        count=0\n",
    "        for thumbnail in thumbnails:\n",
    "            if(count==max_imgs):\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                thumbnail.click()\n",
    "                # wait for image to load\n",
    "                time.sleep(8)\n",
    "            except:\n",
    "                continue\n",
    "            #print(thumbnail)\n",
    "            pop_up_window = driver.find_elements(By.CLASS_NAME,\"jlTjKd\")  \n",
    "            for pop_up_elements in pop_up_window:\n",
    "                if pop_up_elements.tag_name == 'a':\n",
    "                    # print(\"<a> tag obtained\")\n",
    "\n",
    "                    # get all the img tags under <a>\n",
    "                    img_tags = pop_up_elements.find_elements(By.TAG_NAME,\"img\")\n",
    "\n",
    "                    # print(\"img tags obtained\")\n",
    "                    for img in img_tags:\n",
    "                        class_name=img.get_attribute(\"class\")\n",
    "                        if \"iPVvYb\" in class_name.strip():\n",
    "                            image_url=img.get_attribute('src')\n",
    "                            if(image_url not in image_urls):\n",
    "                                if(requests.get(image_url).status_code==200):        \n",
    "                                    image_urls.append(image_url)\n",
    "                                    print(\"Found \",count)\n",
    "                                    count+=1\n",
    "                                else:\n",
    "                                    print(\"not able to load img \")    \n",
    "                                    continue\n",
    "                                \n",
    "                                # f.write(\"Found \" + str(success_count) + \"\\n\")\n",
    "                            else:\n",
    "                                print(\"Found Duplicate\")\n",
    "        \n",
    "        download_images(\"C:\\\\Users\\\\Aarush Raj\\\\OneDrive\\\\Desktop\\\\img2rec\\\\DEEP-CHEF-PROJECT\\\\downloaded_images\",image_urls,recipe_name,recipe_index_csv,no_of_img_to_train)\n",
    "                    \n",
    "        log_urls(image_urls,recipe_index_csv,recipe_name,\"dwd_logs.txt\",no_of_img_to_train)        \n",
    "                # go back to search results\n",
    "        time.sleep(7)        \n",
    "    # close web browser\n",
    "    #print(image_urls)\n",
    "    d_log.close()\n",
    "except Exception as e:\n",
    "    print(\"Exception-\",e)\n",
    "    driver.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicken Tikka Masala</td>\n",
       "      <td>https://www.food.com/recipe/chicken-tikka-masa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naan</td>\n",
       "      <td>https://www.food.com/recipe/naan-203261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicken Curry</td>\n",
       "      <td>https://www.food.com/recipe/chicken-curry-in-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aloo Gobi</td>\n",
       "      <td>https://www.food.com/recipe/aloo-gobi-84324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crock Pot Chicken Vindaloo</td>\n",
       "      <td>https://www.food.com/recipe/crock-pot-chicken-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name  \\\n",
       "0        Chicken Tikka Masala   \n",
       "1                        Naan   \n",
       "2               Chicken Curry   \n",
       "3                   Aloo Gobi   \n",
       "4  Crock Pot Chicken Vindaloo   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.food.com/recipe/chicken-tikka-masa...  \n",
       "1            https://www.food.com/recipe/naan-203261  \n",
       "2  https://www.food.com/recipe/chicken-curry-in-a...  \n",
       "3        https://www.food.com/recipe/aloo-gobi-84324  \n",
       "4  https://www.food.com/recipe/crock-pot-chicken-...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d=pd.read_csv(\"C:\\\\Users\\\\Aarush Raj\\\\OneDrive\\\\Desktop\\\\img2rec\\\\DEEP-CHEF-PROJECT\\\\links_copy_main.csv\")\n",
    "ds=pd.read_csv(\"C:\\\\Users\\\\Aarush Raj\\\\OneDrive\\\\Desktop\\\\img2rec\\\\DEEP-CHEF-PROJECT\\\\links_copy_main.csv\")\n",
    "#dd=pd.read_csv(\"links_copy_main.csv\")\n",
    "ds.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
